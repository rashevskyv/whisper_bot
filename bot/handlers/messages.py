import logging
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode, ChatAction
from telegram.ext import ContextTypes
from bot.utils.helpers import get_ai_provider
from bot.utils.context import context_manager
from bot.utils.media import download_file, extract_audio, cleanup_files
from config import DEFAULT_SETTINGS, BOT_TRIGGERS

logger = logging.getLogger(__name__)

def should_respond(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    chat_type = update.effective_chat.type
    if chat_type == 'private': return True

    message = update.message
    if not message: return False

    if message.reply_to_message and message.reply_to_message.from_user.id == context.bot.id:
        return True

    text = (message.text or message.caption or "").lower()
    bot_username = context.bot.username.lower()
    triggers = BOT_TRIGGERS + [f"@{bot_username}"]
    
    if any(trigger in text for trigger in triggers):
        return True

    return False

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    text = update.message.text
    if not text: return

    if should_respond(update, context):
        await context_manager.save_message(user.id, 'user', text)
        await process_gpt_request(update, context, user.id)

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–∫–∞ —Ñ–æ—Ç–æ: –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –º–µ–Ω—é –≤–∏–±–æ—Ä—É –¥—ñ–π"""
    
    if not should_respond(update, context):
        return

    # –ú–µ–Ω—é –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è, –¥–∞—î–º–æ quote=True, —â–æ–± —Ç–æ—á–Ω–æ –ø—Ä–∏–≤'—è–∑–∞—Ç–∏—Å—è –¥–æ —Ñ–æ—Ç–æ
    keyboard = [
        [
            InlineKeyboardButton("üñº –û–ø–∏—Å–∞—Ç–∏", callback_data="photo_desc"),
            InlineKeyboardButton("üìÑ –¢–µ–∫—Å—Ç (OCR)", callback_data="photo_read")
        ],
        [InlineKeyboardButton("üóë –í–∏–¥–∞–ª–∏—Ç–∏", callback_data="delete_msg")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        "–©–æ –∑—Ä–æ–±–∏—Ç–∏ –∑ —Ü–∏–º –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º?",
        reply_markup=reply_markup,
        quote=True
    )

async def handle_voice_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    chat_type = update.effective_chat.type
    
    if update.message.video and chat_type != 'private':
        if not should_respond(update, context): return

    if update.message.voice:
        file_obj = update.message.voice
        is_video = False
    elif update.message.video_note:
        file_obj = update.message.video_note
        is_video = True
    elif update.message.video:
        file_obj = update.message.video
        is_video = True
    else:
        return

    provider = await get_ai_provider(user.id)
    if not provider:
        if chat_type == 'private': await update.message.reply_text("‚ö†Ô∏è –ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø—É –¥–æ AI.")
        return

    status_msg = None
    if chat_type == 'private':
        status_msg = await update.message.reply_text("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é...")
    
    temp_files = []
    
    try:
        tg_file = await context.bot.get_file(file_obj.file_id)
        input_path = await download_file(tg_file, file_obj.file_id)
        temp_files.append(input_path)

        if is_video:
            if status_msg: await status_msg.edit_text("‚öôÔ∏è –í–∏—Ç—è–≥—É—é –∞—É–¥—ñ–æ...")
            audio_path = await extract_audio(input_path)
            temp_files.append(audio_path)
        else:
            audio_path = input_path

        if status_msg: await status_msg.edit_text("üéô –†–æ–∑–ø—ñ–∑–Ω–∞—é...")
        transcription = await provider.transcribe(audio_path)
        
        if status_msg: await status_msg.delete()

        if transcription:
            await context_manager.save_message(user.id, 'user', f"[–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è]: {transcription}")
            
            reply_markup = None
            if chat_type == 'private':
                keyboard = [
                    [
                        InlineKeyboardButton("ü§ñ –í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ –±–æ—Ç—É", callback_data="run_gpt"),
                        InlineKeyboardButton("üìù –ü—ñ–¥—Å—É–º—É–≤–∞—Ç–∏", callback_data="summarize")
                    ],
                    [InlineKeyboardButton("üóë –í–∏–¥–∞–ª–∏—Ç–∏", callback_data="delete_msg")]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)
            
            await update.message.reply_text(
                f"<code>{transcription}</code>",
                parse_mode=ParseMode.HTML,
                reply_markup=reply_markup
            )

    except Exception as e:
        logger.error(f"Media error: {e}")
        if status_msg: await status_msg.edit_text(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
    finally:
        cleanup_files(temp_files)

async def process_gpt_request(update: Update, context: ContextTypes.DEFAULT_TYPE, user_id: int):
    provider = await get_ai_provider(user_id)
    if not provider: return

    msg_func = update.callback_query.message.reply_text if update.callback_query else update.message.reply_text
    status_msg = await msg_func("‚è≥")
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)

    messages = await context_manager.get_context(user_id, limit=20)
    await stream_response(provider, messages, status_msg, user_id)

async def summarize_text(update: Update, context: ContextTypes.DEFAULT_TYPE, text_to_summarize: str):
    user_id = update.effective_user.id
    provider = await get_ai_provider(user_id)
    if not provider: return

    # –û–ù–û–í–õ–ï–ù–û: –í—ñ–¥–ø–æ–≤—ñ–¥–∞—î–º–æ –Ω–æ–≤–∏–º –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è–º, —â–æ–± –Ω–µ –∑–∞—Ç–∏—Ä–∞—Ç–∏ –∫–Ω–æ–ø–∫–∏
    status_msg = await update.callback_query.message.reply_text("üìù –ê–Ω–∞–ª—ñ–∑—É—é...")
    
    messages = [
        {"role": "system", "content": DEFAULT_SETTINGS['summary_prompt']},
        {"role": "user", "content": text_to_summarize}
    ]
    await stream_response(provider, messages, status_msg, user_id, save_to_history=False)

async def process_photo_analysis(update: Update, context: ContextTypes.DEFAULT_TYPE, mode: str):
    """–û–±—Ä–æ–±–∫–∞ —Ñ–æ—Ç–æ –ø—ñ—Å–ª—è –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –∫–Ω–æ–ø–∫–∏"""
    user_id = update.effective_user.id
    provider = await get_ai_provider(user_id)
    if not provider: return

    # –û—Ç—Ä–∏–º—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ —Ñ–æ—Ç–æ (–Ω–∞ —è–∫–µ –≤—ñ–¥–ø–æ–≤—ñ–ª–æ –Ω–∞—à–µ –º–µ–Ω—é)
    menu_message = update.callback_query.message
    photo_message = menu_message.reply_to_message
    
    # –Ø–∫—â–æ —Ü–µ –ø–µ—Ä–µ—Å–ª–∞–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è, —ñ–Ω–æ–¥—ñ –ª—ñ–Ω–∫ –≤—Ç—Ä–∞—á–∞—î—Ç—å—Å—è, 
    # –∞–ª–µ –ø—Ä–∏ —è–≤–Ω–æ–º—É reply_to_message –≤—ñ–Ω –º–∞—î –±—É—Ç–∏
    if not photo_message:
        await menu_message.reply_text("‚ùå –ü–æ–º–∏–ª–∫–∞: –Ω–µ –º–æ–∂—É –∑–Ω–∞–π—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ñ–æ—Ç–æ.")
        return

    # –®—É–∫–∞—î–º–æ —Ñ–æ—Ç–æ (–∞–±–æ –¥–æ–∫—É–º–µ–Ω—Ç, —è–∫—â–æ –≤—ñ–¥–ø—Ä–∞–≤–∏–ª–∏ —Ñ–∞–π–ª–æ–º)
    photo_file_id = None
    if photo_message.photo:
        photo_file_id = photo_message.photo[-1].file_id
    elif photo_message.document and photo_message.document.mime_type.startswith('image'):
        photo_file_id = photo_message.document.file_id

    if not photo_file_id:
        await menu_message.reply_text("‚ùå –§–æ—Ç–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ (–º–æ–∂–ª–∏–≤–æ, —Ü–µ —Ñ–∞–π–ª –±–µ–∑ –ø—Ä–µ–≤'—é).")
        return

    # –í–Ü–î–ü–†–ê–í–õ–Ø–Ñ–ú–û –ù–û–í–ï –ü–û–í–Ü–î–û–ú–õ–ï–ù–ù–Ø (—Å—Ç–∞—Ä–µ –º–µ–Ω—é –Ω–µ —á—ñ–ø–∞—î–º–æ)
    status_msg = await menu_message.reply_text("üëÄ –î–∏–≤–ª—é—Å—å...", quote=True)
    
    if mode == "desc":
        prompt = "–û–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω–æ, —â–æ –∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —Ü—å–æ–º—É —Ñ–æ—Ç–æ. –Ø–∫—â–æ —î –∂–∞—Ä—Ç - –ø–æ—è—Å–Ω–∏ –π–æ–≥–æ."
        action_log = "[–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø–æ–ø—Ä–æ—Å–∏–≤ –æ–ø–∏—Å–∞—Ç–∏ —Ñ–æ—Ç–æ]"
    elif mode == "read":
        prompt = "–í–∏–ø–∏—à–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç, —è–∫–∏–π —Ç–∏ –±–∞—á–∏—à –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ. –ó–±–µ—Ä–µ–∂–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É. –¢—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç."
        action_log = "[–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø–æ–ø—Ä–æ—Å–∏–≤ –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ç–µ–∫—Å—Ç –∑ —Ñ–æ—Ç–æ]"
    else:
        return

    temp_files = []
    try:
        tg_file = await context.bot.get_file(photo_file_id)
        image_path = await download_file(tg_file, f"photo_{photo_message.message_id}")
        temp_files.append(image_path)

        messages = await context_manager.get_context(user_id, limit=5)
        
        full_response = ""
        last_update_len = 0
        async for chunk in provider.analyze_image(image_path, prompt, messages):
            full_response += chunk
            if len(full_response) - last_update_len > 50:
                try:
                    await status_msg.edit_text(full_response + " ‚ñå")
                    last_update_len = len(full_response)
                except Exception:
                    pass

        try:
            await status_msg.edit_text(full_response, parse_mode=ParseMode.HTML)
        except Exception:
            await status_msg.edit_text(full_response)
            
        await context_manager.save_message(user_id, 'user', action_log)
        await context_manager.save_message(user_id, 'assistant', full_response)

    except Exception as e:
        logger.error(f"Vision error: {e}")
        await status_msg.edit_text(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
    finally:
        cleanup_files(temp_files)

async def stream_response(provider, messages, status_msg, user_id, save_to_history=True):
    full_response = ""
    last_update_len = 0
    try:
        async for chunk in provider.generate_stream(messages, {'model': 'gpt-4o'}):
            full_response += chunk
            if len(full_response) - last_update_len > 50:
                try:
                    await status_msg.edit_text(full_response + " ‚ñå")
                    last_update_len = len(full_response)
                except Exception:
                    pass
        try:
            await status_msg.edit_text(full_response, parse_mode=ParseMode.HTML)
        except Exception:
            await status_msg.edit_text(full_response)
        if save_to_history:
            await context_manager.save_message(user_id, 'assistant', full_response)
    except Exception as e:
        logger.error(f"GPT Error: {e}")
        await status_msg.edit_text(f"‚ùå {str(e)}")

async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    
    # –ü—Ä–æ—Å—Ç–æ –ø—ñ–¥—Å–≤—ñ—á—É—î–º–æ –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è, –∞–ª–µ –Ω–µ –≤–∏–¥–∞–ª—è—î–º–æ –∫–Ω–æ–ø–∫–∏
    if query.data == "delete_msg":
        await query.message.delete()
        
    elif query.data == "run_gpt":
        await query.answer("–í—ñ–¥–ø—Ä–∞–≤–ª—è—é –±–æ—Ç—É...")
        # –¢—É—Ç –∫–Ω–æ–ø–∫–∏ –º–æ–∂–Ω–∞ –ø—Ä–∏–±—Ä–∞—Ç–∏, –∞–±–æ –∑–∞–ª–∏—à–∏—Ç–∏ - —è–∫ —Ö–æ—á–µ—Ç–µ. 
        # –ó–∞—Ä–∞–∑ –∑–∞–ª–∏—à–∞—î–º–æ, –±–æ –≤–∏ –ø—Ä–æ—Å–∏–ª–∏ "buttons should remain". 
        # –ê–ª–µ –∑–∞–∑–≤–∏—á–∞–π –¥–ª—è —Ç–µ–∫—Å—Ç—É —Ü–µ –¥–∏–≤–Ω–æ. –ù–µ—Ö–∞–π –¥–ª—è —Ç–µ–∫—Å—Ç—É (run_gpt) –≤–∏–¥–∞–ª—è—é—Ç—å—Å—è,
        # –∞ –¥–ª—è —Ñ–æ—Ç–æ (desc/read) –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è.
        user = update.effective_user
        await query.message.edit_reply_markup(reply_markup=None) 
        await process_gpt_request(update, context, user.id)

    elif query.data == "summarize":
        await query.answer("–†–æ–±–ª—é –≤–∏–∂–∏–º–∫—É...")
        # –¢—É—Ç –Ω–µ –≤–∏–¥–∞–ª—è—î–º–æ –∫–Ω–æ–ø–∫–∏, —â–æ–± –º–æ–∂–Ω–∞ –±—É–ª–æ —ñ –±–æ—Ç—É –≤—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏
        transcription_text = query.message.text
        if transcription_text:
            await summarize_text(update, context, transcription_text)
        else:
            await query.message.reply_text("‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É.")

    elif query.data == "photo_desc":
        await query.answer("–û–ø–∏—Å—É—é...")
        await process_photo_analysis(update, context, "desc")
        
    elif query.data == "photo_read":
        await query.answer("–ß–∏—Ç–∞—é —Ç–µ–∫—Å—Ç...")
        await process_photo_analysis(update, context, "read")
    
    else:
        await query.answer()